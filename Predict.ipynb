{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "new_model1 = load_model(\"cnn_10epochsO.model\")\n",
    "new_model2 = load_model(\"cnn_10epochsC.model\")\n",
    "new_model3 = load_model(\"cnn_10epochsE.model\")\n",
    "new_model4 = load_model(\"cnn_10epochsA.model\")\n",
    "new_model5 = load_model(\"cnn_10epochsN.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "opt = RMSprop(lr=0.001, rho=0.9, epsilon=None)\n",
    "\n",
    "new_model1.compile(loss='mean_squared_error', \n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "new_model2.compile(loss='mean_squared_error', \n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "new_model3.compile(loss='mean_squared_error', \n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "new_model4.compile(loss='mean_squared_error', \n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "new_model5.compile(loss='mean_squared_error', \n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "data loaded!\n",
      "[[ 0  0  0 ...  0  0 -1]\n",
      " [ 0  0  0 ...  0  0 -1]\n",
      " [ 0  0  0 ...  0  0 -1]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0 -1]\n",
      " [ 0  0  0 ...  0  0 -1]\n",
      " [ 0  0  0 ...  0  0 -1]]\n"
     ]
    }
   ],
   "source": [
    "def get_idx_from_sent(sent, word_idx_map, max_l=51, kernel_size=5):\n",
    "    \"\"\"\n",
    "    Transforms sentence into a list of indices. Pad with zeroes.\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    pad = kernel_size - 1\n",
    "    for i in range(pad):\n",
    "        x.append(0)\n",
    "    words = sent.split()\n",
    "    for word in words:\n",
    "        if word in word_idx_map:\n",
    "            x.append(word_idx_map[word])\n",
    "    while len(x) < max_l+2*pad:\n",
    "        x.append(0)\n",
    "    return x\n",
    "\n",
    "def make_idx_data(revs, word_idx_map, max_l=51, kernel_size=5):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    test = []\n",
    "    for rev in revs:\n",
    "        sent = get_idx_from_sent(rev['text'], word_idx_map, max_l, kernel_size)\n",
    "        sent.append(rev['y'])\n",
    "        test.append(sent)\n",
    "    test = np.array(test, dtype=np.int)\n",
    "    return test\n",
    "\n",
    "\n",
    "print (\"loading data...\")\n",
    "with open(\"imdb-test.pickle\", 'rb') as f:\n",
    "    x = pickle.load(f, encoding='latin')\n",
    "revs, W, word_idx_map, vocab = x[0], x[1], x[2], x[3]\n",
    "print (\"data loaded!\")\n",
    "\n",
    "\n",
    "datasets = make_idx_data(revs, word_idx_map,max_l = 2721,kernel_size=5)\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_X.shape = (468, 2729)\n"
     ]
    }
   ],
   "source": [
    "Nt = datasets.shape[0]\n",
    "test_X = np.zeros((Nt,2729), dtype=np.int)\n",
    "for i in range(Nt):\n",
    "    for j in range(2729):\n",
    "       test_X[i, j] = datasets[i, j]\n",
    "    \n",
    "print ('test_X.shape = {}'.format(test_X.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13093"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X[0][543]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468/468 [==============================] - 9s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "o = new_model1.predict(test_X, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(468, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(o.shape[0]):\n",
    "    o[i][0] = o[i][0]>0.5\n",
    "    o[i][1] = o[i][1]>0.5    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468/468 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "c = new_model2.predict(test_X, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468/468 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "e = new_model3.predict(test_X, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468/468 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "a = new_model4.predict(test_X, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468/468 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "n = new_model5.predict(test_X, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(468):\n",
    "    o[i][0] = int(o[i][0]>0.5)\n",
    "    o[i][1] = int(o[i][1]>0.5)\n",
    "    c[i][0] = int(c[i][0]>0.5)\n",
    "    c[i][1] = int(c[i][1]>0.5)\n",
    "    e[i][0] = int(e[i][0]>0.5)\n",
    "    e[i][1] = int(e[i][1]>0.5)\n",
    "    a[i][0] = int(a[i][0]>0.5)\n",
    "    a[i][1] = int(a[i][1]>0.5)\n",
    "    n[i][0] = int(n[i][0]>0.5)\n",
    "    n[i][1] = int(n[i][1]>0.5) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
