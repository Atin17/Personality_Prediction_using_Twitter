{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cPickle\n",
    "from collections import defaultdict\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003_149.txt</td>\n",
       "      <td>so I don't really know what to type about. I h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003_150.txt</td>\n",
       "      <td>Here it goes. 20 minutes seems like a long tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003_151.txt</td>\n",
       "      <td>Well I decided that I was going to go ahead an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003_152.txt</td>\n",
       "      <td>Right now I am watching tv. I it kinda hard to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003_155.txt</td>\n",
       "      <td>I'm very tired right now. I know that I have n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2003_159.txt</td>\n",
       "      <td>I wonder when my sister is going to be back fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2003_160.txt</td>\n",
       "      <td>There is this annoying noise in the back groun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2003_162.txt</td>\n",
       "      <td>Right now it is 11:25. I am sitting by myself ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2003_164.txt</td>\n",
       "      <td>I wonder why they have a sticker reminding us ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2003_165.txt</td>\n",
       "      <td>okay so I'm sitting here in the computer lab i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2003_166.txt</td>\n",
       "      <td>today was just like every monday and wednesday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2003_167.txt</td>\n",
       "      <td>English is my second language. probably I'll h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2003_168.txt</td>\n",
       "      <td>I am so upset with myself today. I am so far b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2003_169.txt</td>\n",
       "      <td>I am in my dorm lost in my own thoughts. My ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2003_170.txt</td>\n",
       "      <td>Ok so what am I doing right now?  This is real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2003_171.txt</td>\n",
       "      <td>I really don't know what to type. I wonder wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2003_174.txt</td>\n",
       "      <td>Okay, let's see. I'm really really stressed ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2003_175.txt</td>\n",
       "      <td>I hope that this isn't a big deal, as I have t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2003_176.txt</td>\n",
       "      <td>my room seems nice, I mean it's not like home ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2003_179.txt</td>\n",
       "      <td>SO before I started writing this, I was eating...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2003_181.txt</td>\n",
       "      <td>I am writing this for psychology class. I'm gl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2003_183.txt</td>\n",
       "      <td>Today has been a pretty good day. I am a littl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2003_184.txt</td>\n",
       "      <td>Well I'm sitting here typing on the computer i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2003_185.txt</td>\n",
       "      <td>ok, at this very moment, I'm am in pain, emoti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2003_186.txt</td>\n",
       "      <td>I'm just sitting here typing. Mu light is pret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2003_188.txt</td>\n",
       "      <td>My computer is spiffy. I decided to name it Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2003_189.txt</td>\n",
       "      <td>Well this weekend has been really different. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2003_191.txt</td>\n",
       "      <td>today is a bad day. my boyfriend and I of 2 ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2003_192.txt</td>\n",
       "      <td>This is different, I always thought stream of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2003_193.txt</td>\n",
       "      <td>I'm so tired right now. I wish I could just sl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>2004_453.txt</td>\n",
       "      <td>I always have a million thoughts going on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>2004_455.txt</td>\n",
       "      <td>Hello, I don't know why I feel that I have to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>2004_456.txt</td>\n",
       "      <td>I'm sitting in my dorm room and it's very...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>2004_457.txt</td>\n",
       "      <td>I hate escalators. Don't know why. I've a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>2004_458.txt</td>\n",
       "      <td>it is a beautiful day outside and I hope to en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>2004_460.txt</td>\n",
       "      <td>Ok. just got done crying because of stupi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>2004_461.txt</td>\n",
       "      <td>Today is the first football game, I'm pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>2004_462.txt</td>\n",
       "      <td>I do not feel well at all, I wonder if it was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>2004_464.txt</td>\n",
       "      <td>it is really cold in my room, my roommate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>2004_467.txt</td>\n",
       "      <td>Well, I woke up this morning scared becau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>2004_468.txt</td>\n",
       "      <td>so yeah. I finally get to the point where I fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>2004_470.txt</td>\n",
       "      <td>I am watching t. v. and waiting for my friends...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>2004_471.txt</td>\n",
       "      <td>I am watching an italian movie called \"r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>2004_472.txt</td>\n",
       "      <td>I am excited about being a columnist, not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>2004_475.txt</td>\n",
       "      <td>Stream on consciousness, this is somethin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>2004_476.txt</td>\n",
       "      <td>NFL kickoff tonight. should be fun to wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>2004_478.txt</td>\n",
       "      <td>Ok so I just got back from a four hour study h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>2004_480.txt</td>\n",
       "      <td>When I got online tonight I was prompted wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>2004_481.txt</td>\n",
       "      <td>The speakers that are connected to my com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>2004_482.txt</td>\n",
       "      <td>Well I guess I will just write about my c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>2004_483.txt</td>\n",
       "      <td>Yaaaaay. I'm doing psychology things. I'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>2004_484.txt</td>\n",
       "      <td>I have so much work to do and it all seems to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>2004_487.txt</td>\n",
       "      <td>I just got done doing some homework for c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>2004_490.txt</td>\n",
       "      <td>I wasn't expecting to get sick, but for s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>2004_492.txt</td>\n",
       "      <td>well I am sitting here in my bed just before 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>2004_493.txt</td>\n",
       "      <td>I'm home. wanted to go to bed but remembe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>2004_494.txt</td>\n",
       "      <td>Stream of consiousnesssskdj. How do you s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>2004_497.txt</td>\n",
       "      <td>It is Wednesday, December 8th and a lot has be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>2004_498.txt</td>\n",
       "      <td>Man this week has been hellish. Anyways, now i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>2004_499.txt</td>\n",
       "      <td>I have just gotten off the phone with brady. I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          #AUTHID                                               TEXT\n",
       "0    2003_149.txt  so I don't really know what to type about. I h...\n",
       "1    2003_150.txt  Here it goes. 20 minutes seems like a long tim...\n",
       "2    2003_151.txt  Well I decided that I was going to go ahead an...\n",
       "3    2003_152.txt  Right now I am watching tv. I it kinda hard to...\n",
       "4    2003_155.txt  I'm very tired right now. I know that I have n...\n",
       "5    2003_159.txt  I wonder when my sister is going to be back fr...\n",
       "6    2003_160.txt  There is this annoying noise in the back groun...\n",
       "7    2003_162.txt  Right now it is 11:25. I am sitting by myself ...\n",
       "8    2003_164.txt  I wonder why they have a sticker reminding us ...\n",
       "9    2003_165.txt  okay so I'm sitting here in the computer lab i...\n",
       "10   2003_166.txt  today was just like every monday and wednesday...\n",
       "11   2003_167.txt  English is my second language. probably I'll h...\n",
       "12   2003_168.txt  I am so upset with myself today. I am so far b...\n",
       "13   2003_169.txt  I am in my dorm lost in my own thoughts. My ro...\n",
       "14   2003_170.txt  Ok so what am I doing right now?  This is real...\n",
       "15   2003_171.txt  I really don't know what to type. I wonder wha...\n",
       "16   2003_174.txt  Okay, let's see. I'm really really stressed ou...\n",
       "17   2003_175.txt  I hope that this isn't a big deal, as I have t...\n",
       "18   2003_176.txt  my room seems nice, I mean it's not like home ...\n",
       "19   2003_179.txt  SO before I started writing this, I was eating...\n",
       "20   2003_181.txt  I am writing this for psychology class. I'm gl...\n",
       "21   2003_183.txt  Today has been a pretty good day. I am a littl...\n",
       "22   2003_184.txt  Well I'm sitting here typing on the computer i...\n",
       "23   2003_185.txt  ok, at this very moment, I'm am in pain, emoti...\n",
       "24   2003_186.txt  I'm just sitting here typing. Mu light is pret...\n",
       "25   2003_188.txt  My computer is spiffy. I decided to name it Ma...\n",
       "26   2003_189.txt  Well this weekend has been really different. I...\n",
       "27   2003_191.txt  today is a bad day. my boyfriend and I of 2 ye...\n",
       "28   2003_192.txt  This is different, I always thought stream of ...\n",
       "29   2003_193.txt  I'm so tired right now. I wish I could just sl...\n",
       "..            ...                                                ...\n",
       "438  2004_453.txt       I always have a million thoughts going on...\n",
       "439  2004_455.txt  Hello, I don't know why I feel that I have to ...\n",
       "440  2004_456.txt       I'm sitting in my dorm room and it's very...\n",
       "441  2004_457.txt       I hate escalators. Don't know why. I've a...\n",
       "442  2004_458.txt  it is a beautiful day outside and I hope to en...\n",
       "443  2004_460.txt       Ok. just got done crying because of stupi...\n",
       "444  2004_461.txt       Today is the first football game, I'm pre...\n",
       "445  2004_462.txt  I do not feel well at all, I wonder if it was ...\n",
       "446  2004_464.txt       it is really cold in my room, my roommate...\n",
       "447  2004_467.txt       Well, I woke up this morning scared becau...\n",
       "448  2004_468.txt  so yeah. I finally get to the point where I fe...\n",
       "449  2004_470.txt  I am watching t. v. and waiting for my friends...\n",
       "450  2004_471.txt        I am watching an italian movie called \"r...\n",
       "451  2004_472.txt       I am excited about being a columnist, not...\n",
       "452  2004_475.txt       Stream on consciousness, this is somethin...\n",
       "453  2004_476.txt       NFL kickoff tonight. should be fun to wat...\n",
       "454  2004_478.txt  Ok so I just got back from a four hour study h...\n",
       "455  2004_480.txt    When I got online tonight I was prompted wit...\n",
       "456  2004_481.txt       The speakers that are connected to my com...\n",
       "457  2004_482.txt       Well I guess I will just write about my c...\n",
       "458  2004_483.txt       Yaaaaay. I'm doing psychology things. I'm...\n",
       "459  2004_484.txt  I have so much work to do and it all seems to ...\n",
       "460  2004_487.txt       I just got done doing some homework for c...\n",
       "461  2004_490.txt       I wasn't expecting to get sick, but for s...\n",
       "462  2004_492.txt  well I am sitting here in my bed just before 1...\n",
       "463  2004_493.txt       I'm home. wanted to go to bed but remembe...\n",
       "464  2004_494.txt       Stream of consiousnesssskdj. How do you s...\n",
       "465  2004_497.txt  It is Wednesday, December 8th and a lot has be...\n",
       "466  2004_498.txt  Man this week has been hellish. Anyways, now i...\n",
       "467  2004_499.txt  I have just gotten off the phone with brady. I...\n",
       "\n",
       "[468 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv('test.csv',encoding = \"latin\")\n",
    "\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_train_test(data_train, train_ratio = 0.8, clean_string=True):\n",
    "    \"\"\"\n",
    "    Loads data and split into train and test sets.\n",
    "    \"\"\"\n",
    "    revs = []\n",
    "    vocab = defaultdict(float)\n",
    "    # Pre-process train data set\n",
    "    for i in xrange(data_train.shape[0]):\n",
    "        line = data_train['TEXT'][i]\n",
    "        y = data_train['cNEU'][i]\n",
    "        rev = []\n",
    "        rev.append(line.strip())\n",
    "        if clean_string:\n",
    "            orig_rev = clean_str(' '.join(rev))\n",
    "        else:\n",
    "            orig_rev = ' '.join(rev).lower()\n",
    "        words = set(orig_rev.split())\n",
    "        for word in words:\n",
    "            vocab[word] += 1\n",
    "        datum  = {'y': y, \n",
    "                  'text': orig_rev,\n",
    "                  'num_words': len(orig_rev.split()),\n",
    "                  'split': int(np.random.rand() < train_ratio)}\n",
    "        revs.append(datum)\n",
    "                \n",
    "    return revs, vocab\n",
    "\n",
    "    \n",
    "def get_W(word_vecs, k=300):\n",
    "    \"\"\"\n",
    "    Get word matrix. W[i] is the vector for word indexed by i\n",
    "    \"\"\"\n",
    "    vocab_size = len(word_vecs)\n",
    "    word_idx_map = dict()\n",
    "    W = np.zeros(shape=(vocab_size+1, k), dtype=np.float32)\n",
    "    W[0] = np.zeros(k, dtype=np.float32)\n",
    "    i = 1\n",
    "    for word in word_vecs:\n",
    "        W[i] = word_vecs[word]\n",
    "        word_idx_map[word] = i\n",
    "        i += 1\n",
    "    return W, word_idx_map\n",
    "\n",
    "def load_bin_vec(fname, vocab):\n",
    "    \"\"\"\n",
    "    Loads 300x1 word vecs from Google (Mikolov) word2vec\n",
    "    \"\"\"\n",
    "    word_vecs = {}\n",
    "    with open(fname, 'rb') as f:\n",
    "        header = f.readline()\n",
    "        vocab_size, layer1_size = map(int, header.split())\n",
    "        binary_len = np.dtype('float32').itemsize * layer1_size\n",
    "        for line in xrange(vocab_size):\n",
    "            word = []\n",
    "            while True:\n",
    "                ch = f.read(1)\n",
    "                if ch == ' ':\n",
    "                    word = ''.join(word)\n",
    "                    break\n",
    "                if ch != '\\n':\n",
    "                    word.append(ch)   \n",
    "            if word in vocab:\n",
    "                word_vecs[word] = np.fromstring(f.read(binary_len), dtype='float32')  \n",
    "            else:\n",
    "                f.read(binary_len)\n",
    "    return word_vecs\n",
    "\n",
    "def add_unknown_words(word_vecs, vocab, min_df=1, k=300):\n",
    "    \"\"\"\n",
    "    For words that occur in at least min_df documents, create a separate word vector.    \n",
    "    0.25 is chosen so the unknown vectors have (approximately) same variance as pre-trained ones\n",
    "    \"\"\"\n",
    "    for word in vocab:\n",
    "        if word not in word_vecs and vocab[word] >= min_df:\n",
    "            word_vecs[word] = np.random.uniform(-0.25,0.25,k)  \n",
    "\n",
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for dataset\n",
    "    Every dataset is lower cased except\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)     \n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string) \n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string) \n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string) \n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string) \n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string) \n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string) \n",
    "    string = re.sub(r\",\", \" , \", string) \n",
    "    string = re.sub(r\"!\", \" ! \", string) \n",
    "    string = re.sub(r\"\\(\", \" \\( \", string) \n",
    "    string = re.sub(r\"\\)\", \" \\) \", string) \n",
    "    string = re.sub(r\"\\?\", \" \\? \", string) \n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)    \n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded!\n",
      "number of sentences: 2467\n",
      "vocab size: 30417\n",
      "max sentence length: 2721\n",
      "loading word2vec vectors..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python27\\lib\\site-packages\\ipykernel_launcher.py:63: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "C:\\Python27\\lib\\site-packages\\ipykernel_launcher.py:62: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " word2vec loaded!\n",
      "num words already in word2vec: 22699\n",
      "dataset created!\n"
     ]
    }
   ],
   "source": [
    "w2v_file = 'GoogleNews-vectors-negative300.bin'\n",
    "\n",
    "revs, vocab = build_data_train_test(data_train, train_ratio=0.9, clean_string=True)\n",
    "max_l = np.max(pd.DataFrame(revs)['num_words'])\n",
    "print 'data loaded!'\n",
    "print 'number of sentences: ' + str(len(revs))\n",
    "print 'vocab size: ' + str(len(vocab))\n",
    "print 'max sentence length: ' + str(max_l)\n",
    "print 'loading word2vec vectors...',\n",
    "w2v = load_bin_vec(w2v_file, vocab)\n",
    "print 'word2vec loaded!'\n",
    "print 'num words already in word2vec: ' + str(len(w2v))\n",
    "add_unknown_words(w2v, vocab)\n",
    "W, word_idx_map = get_W(w2v)\n",
    "cPickle.dump([revs, W, word_idx_map, vocab], open('imdb-train-val-testN.pickle', 'wb'))\n",
    "print 'dataset created!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
